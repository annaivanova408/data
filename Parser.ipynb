{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the URL of the webpage you want to scrape\n",
    "url = 'https://www.banki.ru/banks/ratings/?BANK_ID=195706&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0&date1=2016-10-01&date2=2016-09-01'\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the webpage\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all tables on the webpage\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Initialize a dictionary to hold DataFrames for each table\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over each table, extract data, and store in a DataFrame\n",
    "for i, table in enumerate(tables):\n",
    "    data = []\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        cols = [col.text.strip() for col in cols]\n",
    "        data.append(cols)\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs[f'Table_{i+1}'] = df\n",
    "\n",
    "# Write each DataFrame to a separate sheet in an Excel file\n",
    "with pd.ExcelWriter('output.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
