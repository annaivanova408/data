{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed023580",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'collections' has no attribute 'Callable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Parse the HTML content of the webpage\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Find all tables on the webpage\u001b[39;00m\n\u001b[1;32m     15\u001b[0m tables \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:215\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed()\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParserRejectedMarkup:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:239\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_feed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mfeed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/builder/_htmlparser.py:164\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    162\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     parser\u001b[38;5;241m.\u001b[39mfeed(markup)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTMLParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;167;01mRuntimeWarning\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms built-in HTMLParser cannot parse the given document. This is not a bug in Beautiful Soup. The best solution is to install an external parser (lxml or html5lib), and use Beautiful Soup with that parser. See http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser for help.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoahead(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/html/parser.py:178\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    176\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_pi(i)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m--> 178\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_html_declaration(i)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m n:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/html/parser.py:269\u001b[0m, in \u001b[0;36mHTMLParser.parse_html_declaration\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gtpos \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_decl(rawdata[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m:gtpos])\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/builder/_htmlparser.py:109\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_decl\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    107\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\u001b[38;5;241m.\u001b[39mhandle_data(data)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\u001b[38;5;241m.\u001b[39mendData(Doctype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:315\u001b[0m, in \u001b[0;36mBeautifulSoup.endData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    314\u001b[0m o \u001b[38;5;241m=\u001b[39m containerClass(current_data)\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_was_parsed(o)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:320\u001b[0m, in \u001b[0;36mBeautifulSoup.object_was_parsed\u001b[0;34m(self, o, parent, most_recent_element)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add an object to the parse tree.\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m parent \u001b[38;5;241m=\u001b[39m parent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrentTag\n\u001b[0;32m--> 320\u001b[0m previous_element \u001b[38;5;241m=\u001b[39m most_recent_element \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_most_recent_element\n\u001b[1;32m    322\u001b[0m next_element \u001b[38;5;241m=\u001b[39m previous_sibling \u001b[38;5;241m=\u001b[39m next_sibling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, Tag):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/element.py:1001\u001b[0m, in \u001b[0;36mTag.__getattr__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# We special case contents to avoid recursion.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tag\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind(tag)\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, tag))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/element.py:1238\u001b[0m, in \u001b[0;36mTag.find\u001b[0;34m(self, name, attrs, recursive, text, **kwargs)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return only the first child of this Tag matching the given\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;124;03mcriteria.\"\"\"\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_all(name, attrs, recursive, text, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l:\n\u001b[1;32m   1240\u001b[0m     r \u001b[38;5;241m=\u001b[39m l[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/element.py:1259\u001b[0m, in \u001b[0;36mTag.find_all\u001b[0;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m recursive:\n\u001b[1;32m   1258\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\n\u001b[0;32m-> 1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_all(name, attrs, text, limit, generator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/element.py:516\u001b[0m, in \u001b[0;36mPageElement._find_all\u001b[0;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     strainer \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     strainer \u001b[38;5;241m=\u001b[39m SoupStrainer(name, attrs, text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m limit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attrs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;66;03m# Optimization to find all tags.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/element.py:1560\u001b[0m, in \u001b[0;36mSoupStrainer.__init__\u001b[0;34m(self, name, attrs, text, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m     normalized_attrs[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_search_value(value)\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;241m=\u001b[39m normalized_attrs\n\u001b[0;32m-> 1560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_search_value(text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/element.py:1565\u001b[0m, in \u001b[0;36mSoupStrainer._normalize_search_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalize_search_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;66;03m# Leave it alone if it's a Unicode string, a callable, a\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;66;03m# regular expression, a boolean, or None.\u001b[39;00m\n\u001b[0;32m-> 1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, collections\u001b[38;5;241m.\u001b[39mCallable) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1566\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# If it's a bytestring, convert it to Unicode, treating it as UTF-8.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'collections' has no attribute 'Callable'"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the URL of the webpage you want to scrape\n",
    "url = 'https://www.banki.ru/banks/ratings/?BANK_ID=195706&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0&date1=2016-10-01&date2=2016-09-01'\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the webpage\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all tables on the webpage\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Initialize a dictionary to hold DataFrames for each table\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over each table, extract data, and store in a DataFrame\n",
    "for i, table in enumerate(tables):\n",
    "    data = []\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        cols = [col.text.strip() for col in cols]\n",
    "        data.append(cols)\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs[f'Table_{i+1}'] = df\n",
    "\n",
    "# Write each DataFrame to a separate sheet in an Excel file\n",
    "with pd.ExcelWriter('output8.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b73e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
